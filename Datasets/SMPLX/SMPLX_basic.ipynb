{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMPLX\n",
    "## Description\n",
    "\n",
    "*SMPL-X* (SMPL eXpressive) is a unified body model with shape parameters trained jointly for the\n",
    "face, hands and body. *SMPL-X* uses standard vertex based linear blend skinning with learned corrective blend\n",
    "shapes, has N = 10, 475 vertices and K = 54 joints,\n",
    "which include joints for the neck, jaw, eyeballs and fingers. \n",
    "SMPL-X is defined by a function M(Œ∏, Œ≤, œà), where Œ∏ is the pose parameters, Œ≤ the shape parameters and\n",
    "œà the facial expression parameters.\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install the model please follow the next steps in the specified order:\n",
    "1. To install from PyPi simply run: \n",
    "  ```Shell\n",
    "  pip install smplx[all]\n",
    "  ```\n",
    "2. Clone this repository and install it using the *setup.py* script: \n",
    "```Shell\n",
    "git clone https://github.com/vchoutas/smplx\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "## Downloading the model\n",
    "\n",
    "To download the *SMPL-X* model go to [this project website](https://smpl-x.is.tue.mpg.de) and register to get access to the downloads section. \n",
    "\n",
    "To download the *SMPL+H* model go to [this project website](http://mano.is.tue.mpg.de) and register to get access to the downloads section. \n",
    "\n",
    "To download the *SMPL* model go to [this](http://smpl.is.tue.mpg.de) (male and female models) and [this](http://smplify.is.tue.mpg.de) (gender neutral model) project website and register to get access to the downloads section. \n",
    "\n",
    "## Loading SMPL-X, SMPL+H and SMPL\n",
    "\n",
    "### SMPL and SMPL+H setup\n",
    "\n",
    "The loader gives the option to use any of the SMPL-X, SMPL+H, SMPL, and MANO models. Depending on the model you want to use, please follow the respective download instructions. To switch between MANO, SMPL, SMPL+H and SMPL-X just change the *model_path* or *model_type* parameters. For more details please check the docs of the model classes.\n",
    "Before using SMPL and SMPL+H you should follow the instructions in [tools/README.md](./tools/README.md) to remove the\n",
    "Chumpy objects from both model pkls, as well as merge the MANO parameters with SMPL+H.\n",
    "\n",
    "### Model loading \n",
    "\n",
    "You can either use the [create](https://github.com/vchoutas/smplx/blob/c63c02b478c5c6f696491ed9167e3af6b08d89b1/smplx/body_models.py#L54)\n",
    "function from [body_models](./smplx/body_models.py) or directly call the constructor for the \n",
    "[SMPL](https://github.com/vchoutas/smplx/blob/c63c02b478c5c6f696491ed9167e3af6b08d89b1/smplx/body_models.py#L106), \n",
    "[SMPL+H](https://github.com/vchoutas/smplx/blob/c63c02b478c5c6f696491ed9167e3af6b08d89b1/smplx/body_models.py#L395) and \n",
    "[SMPL-X](https://github.com/vchoutas/smplx/blob/c63c02b478c5c6f696491ed9167e3af6b08d89b1/smplx/body_models.py#L628) model. The path to the model can either be the path to the file with the parameters or a directory with the following structure:\n",
    "```bash\n",
    "models\n",
    "‚îú‚îÄ‚îÄ smpl\n",
    "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ SMPL_FEMALE.pkl\n",
    "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ SMPL_MALE.pkl\n",
    "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ SMPL_NEUTRAL.pkl\n",
    "‚îú‚îÄ‚îÄ smplh\n",
    "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ SMPLH_FEMALE.pkl\n",
    "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ SMPLH_MALE.pkl\n",
    "‚îú‚îÄ‚îÄ mano\n",
    "|   ‚îú‚îÄ‚îÄ MANO_RIGHT.pkl\n",
    "|   ‚îî‚îÄ‚îÄ MANO_LEFT.pkl\n",
    "‚îî‚îÄ‚îÄ smplx\n",
    "    ‚îú‚îÄ‚îÄ SMPLX_FEMALE.npz\n",
    "    ‚îú‚îÄ‚îÄ SMPLX_FEMALE.pkl\n",
    "    ‚îú‚îÄ‚îÄ SMPLX_MALE.npz\n",
    "    ‚îú‚îÄ‚îÄ SMPLX_MALE.pkl\n",
    "    ‚îú‚îÄ‚îÄ SMPLX_NEUTRAL.npz\n",
    "    ‚îî‚îÄ‚îÄ SMPLX_NEUTRAL.pkl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "\n",
    "### Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages you may use very often.\n",
    "import torch\n",
    "import numpy as np\n",
    "from smplx import SMPLX\n",
    "# from pytorch3d import transforms  # You may use this package when performing rotation representation transformation.\n",
    "\n",
    "# Things you don't need to care about. They are just for driving the tutorials.\n",
    "from utils.path_manager_smplx import PathManager_SMPLX\n",
    "from utils.wis3d_utils import HWis3D as Wis3D\n",
    "\n",
    "from skeleton_structure import Skeleton_SMPL24 as Skeleton_SMPLX22\n",
    "\n",
    "pm = PathManager_SMPLX()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SMPLX model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMPLX has different models weights for different genders. Make sure you use the correct model for your project.\n",
    "\n",
    "Usually, we just use the neutral model if we can't access the gender information. \n",
    "\n",
    "Here, we will just use neutral model for simplicity. You can try the other genders if you want. You can just re-assign the `body_model` variable in the next cell and re-run the remaining cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 150\n",
    "body_models = {}\n",
    "genders = ['neutral', 'female', 'male']  # case insensitive\n",
    "\n",
    "# all joints\n",
    "# for gender in genders:\n",
    "#     body_models[gender] = SMPLX(\n",
    "#         model_path = pm.root_dataset / 'smplx' / 'models' / 'smplx',\n",
    "#         gender='neutral',\n",
    "#         use_hands=True,\n",
    "#         use_face=True,\n",
    "#         use_face_contour=True,\n",
    "#         num_pca_comps=6,\n",
    "#         use_pca=True,\n",
    "#         ext='npz'\n",
    "#     )\n",
    "\n",
    "# only contain body joints (bug)\n",
    "for gender in genders:\n",
    "    body_models[gender] = SMPLX(\n",
    "        model_path = pm.root_dataset / 'smplx' / 'models' / 'smplx',\n",
    "        gender='neutral',\n",
    "        use_hands=False,\n",
    "        use_face=False,\n",
    "        use_face_contour=False,\n",
    "        num_pca_comps=0,\n",
    "        use_pca=False,\n",
    "        ext='npz',\n",
    "        batch_size=B\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare some parameters for later inference.\n",
    "body_model : SMPLX = body_models['neutral']  # use neutral for example\n",
    "\n",
    "# Prepare mesh template for later visualization.\n",
    "# Tips: mesh = vertices + faces, and the faces are the indices of vertices, which won't change across SMPL's outputs.\n",
    "mesh_temp : np.ndarray = body_model.faces  # (13776, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMPLX Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 117, 3]) torch.Size([150, 10475, 3])\n"
     ]
    }
   ],
   "source": [
    "# Inference.\n",
    "betas         = torch.zeros(B, 10)          # ‰ΩìÂûãÁ≥ªÊï∞\n",
    "global_orient = torch.zeros(B, 3)           # Ê†πÂÖ≥ËäÇÊóãËΩ¨ axis-angle\n",
    "body_pose     = torch.zeros(B, 21, 3)       # ÂÖ∂‰ΩôË∫´‰ΩìÂÖ≥ËäÇ\n",
    "left_hand_pose  = torch.zeros(B, 6)         # ÊâãÈÉ® PCA\n",
    "right_hand_pose = torch.zeros(B, 6)\n",
    "jaw_pose      = torch.zeros(B, 3)\n",
    "leye_pose     = torch.zeros(B, 3)\n",
    "reye_pose     = torch.zeros(B, 3)\n",
    "expression    = torch.zeros(B, 10)\n",
    "transl       = torch.zeros(B, 3)\n",
    "\n",
    "# ---------------------------\n",
    "# ÂâçÂêëÊé®ÁêÜ\n",
    "# ---------------------------\n",
    "# all joints\n",
    "# smpl_out = body_model(\n",
    "#     betas=betas,\n",
    "#     global_orient=global_orient,\n",
    "#     body_pose=body_pose,\n",
    "#     left_hand_pose=left_hand_pose,\n",
    "#     right_hand_pose=right_hand_pose,\n",
    "#     jaw_pose=jaw_pose,\n",
    "#     leye_pose=leye_pose,\n",
    "#     reye_pose=reye_pose,\n",
    "#     expression=expression,\n",
    "#     transl=transl\n",
    "# )\n",
    "\n",
    "# only contain body joints (bug)\n",
    "smpl_out = body_model(\n",
    "    betas=betas,\n",
    "    global_orient=global_orient,\n",
    "    body_pose=body_pose,\n",
    "    transl=transl\n",
    ")\n",
    "\n",
    "# Check output.\n",
    "joints : torch.Tensor = smpl_out.joints    # [150, 117, 3]\n",
    "verts  : torch.Tensor = smpl_out.vertices  # [150, 10475, 3]\n",
    "print(joints.shape, verts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMPLX Skeleton\n",
    "\n",
    "SMPLX has a 22-body-joints. We can get the joints position from the SMPLX model's output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joints' index of SMPLX model is shown in file [smplx/smplx/joint_names.py](./smplx/smplx/joint_names.py). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = [\n",
    "    [0, 1, 4, 7, 10],        # left leg\n",
    "    [0, 2, 5, 8, 11],        # right leg\n",
    "    [0, 3, 6, 9, 12, 15],    # spine & head\n",
    "    [12, 13, 16, 18, 20],    # left arm\n",
    "    [12, 14, 17, 19, 21],    # right arm\n",
    "]\n",
    "\n",
    "bones = [\n",
    "    [0, 1], [1, 4], [4, 7], [7, 10], # left leg\n",
    "    [0, 2], [2, 5], [5, 8], [8, 11], # right leg\n",
    "    [0, 3], [3, 6], [6, 9], [9, 12], [12, 15], # spine & head\n",
    "    [12, 13], [13, 16], [16, 18], [18, 20], # left arm\n",
    "    [12, 14], [14, 17], [17, 19], [19, 21], # right arm\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMPLX Parameters\n",
    "\n",
    "The SMPL-X model takes several key parameters that control the **shape**, **pose**, and **translation** of the human mesh.\n",
    "Here we summarize the most important parameters used in the forward pass:\n",
    "\n",
    "1. **`betas`** (Tensor, shape `[B, N_b]`)\n",
    "   Controls the **body shape** of the model.\n",
    "   Each element in `betas` corresponds to one shape basis learned from real body scans.\n",
    "   Changing `betas` makes the body fatter, thinner, taller, etc.\n",
    "\n",
    "2. **`global_orient`** (Tensor, shape `[B, 3]`)\n",
    "   Defines the **global rotation** of the entire body in *axis-angle* format.\n",
    "   It controls the overall orientation of the character (e.g., facing front, left, right).\n",
    "\n",
    "3. **`body_pose`** (Tensor, shape `[B, J√ó3]`)\n",
    "   Specifies the **relative rotations** of body joints (excluding hands, face, etc.) in *axis-angle* format.\n",
    "   This parameter defines how the torso, arms, and legs are posed relative to the root (`pelvis`).\n",
    "\n",
    "4. **`transl`** (Tensor, shape `[B, 3]`)\n",
    "   Represents the **global translation** of the body in 3D space.\n",
    "   It shifts the entire mesh position without affecting its orientation or pose (e.g., moving the character to another place).\n",
    "\n",
    "\n",
    "\n",
    "### Optional Parameters\n",
    "\n",
    "Besides the four main parameters above, SMPL-X also supports additional inputs for more detailed modeling:\n",
    "\n",
    "| Parameter                           | Description                                                         |\n",
    "| ----------------------------------- | ------------------------------------------------------------------- |\n",
    "| `left_hand_pose`, `right_hand_pose` | 15-joint hand rotations (PCA coefficients or axis-angle).           |\n",
    "| `jaw_pose`                          | Jaw rotation in axis-angle format, for mouth movement.              |\n",
    "| `leye_pose`, `reye_pose`            | Eye rotations, for gaze direction.                                  |\n",
    "| `expression`                        | Expression blendshape coefficients, controlling facial expressions. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. betas | $\\beta \\in \\R^{||\\beta||}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betas control the shape of the model. Usually we use the default 10 shape coefficients. It depends on the model you load.\n",
    "\n",
    "You may see this(below) before, that means you are using a model with 10 shape coefficients.\n",
    "\n",
    "> \"WARNING: You are using a SMPL model, with only 10 shape coefficients.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn_betas(\n",
    "    selected_component : int = 0,\n",
    "    lower_bound : int = -5,\n",
    "    upper_bound : int = +5,\n",
    "):\n",
    "    def make_fake_data():\n",
    "        fake_betas = torch.zeros(B, 10)\n",
    "        fake_betas[:, selected_component] = torch.linspace(lower_bound, upper_bound, B)\n",
    "        return fake_betas\n",
    "    fake_betas = make_fake_data()\n",
    "    print(fake_betas)\n",
    "\n",
    "    # Inference.\n",
    "    smpl_out = body_model(\n",
    "            betas         = fake_betas,             # shape coefficients\n",
    "            global_orient = torch.zeros(B, 1, 3),   # axis-angle representation\n",
    "            body_pose     = torch.zeros(B, 21, 3),  # axis-angle representation\n",
    "            transl        = torch.zeros(B, 3),\n",
    "        )\n",
    "\n",
    "    # Check output.\n",
    "    joints : torch.Tensor = smpl_out.joints    # (B, 117, 3)\n",
    "    verts  : torch.Tensor = smpl_out.vertices  # (B, 10475, 3)\n",
    "    faces  : np.ndarray   = body_model.faces   # (20908, 3)\n",
    "    print(joints.shape)\n",
    "    print(verts.shape)\n",
    "    print(faces.shape)\n",
    "\n",
    "\n",
    "    def visualize_results():\n",
    "        \"\"\" This part is to visualize the results. You are supposed to ignore this part. \"\"\"\n",
    "        shape_wis3d = Wis3D(\n",
    "                pm.outputs / 'wis3d',\n",
    "                'SMPLX-parameters-beta',\n",
    "            )\n",
    "\n",
    "        shape_wis3d.add_motion_verts(\n",
    "            verts  = verts,\n",
    "            name   = f'betas[:, {selected_component}] from {lower_bound} to {upper_bound}',\n",
    "            offset = 0,\n",
    "        )\n",
    "        shape_wis3d.add_motion_mesh(\n",
    "            verts  = verts,\n",
    "            faces  = faces,\n",
    "            name   = f'surface: betas[:, {selected_component}] from {lower_bound} to {upper_bound}',\n",
    "            offset = 0,\n",
    "        )\n",
    "        shape_wis3d.add_motion_skel(\n",
    "            joints = joints[:, :24],\n",
    "            bones  = Skeleton_SMPLX22.bones,\n",
    "            colors = Skeleton_SMPLX22.bone_colors,\n",
    "            name   = f'skeleton: betas[:, {selected_component}] from {lower_bound} to {upper_bound}',\n",
    "            offset = 0,\n",
    "        )\n",
    "    visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the effects of the changes on certain coefficient.\n",
    "\n",
    "Here, `learn_betas(k)` means we will visualize the SMPL outputs when the k-th coefficient is changed from -5 to +5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-4.9329,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-4.8658,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 4.8658,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 4.9329,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 5.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([150, 117, 3])\n",
      "torch.Size([150, 10475, 3])\n",
      "(20908, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn_betas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m learn_betas(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m learn_betas(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 54\u001b[0m, in \u001b[0;36mlearn_betas\u001b[0;34m(selected_component, lower_bound, upper_bound)\u001b[0m\n\u001b[1;32m     41\u001b[0m     shape_wis3d\u001b[38;5;241m.\u001b[39madd_motion_mesh(\n\u001b[1;32m     42\u001b[0m         verts  \u001b[38;5;241m=\u001b[39m verts,\n\u001b[1;32m     43\u001b[0m         faces  \u001b[38;5;241m=\u001b[39m faces,\n\u001b[1;32m     44\u001b[0m         name   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface: betas[:, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_component\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlower_bound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupper_bound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m         offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m     shape_wis3d\u001b[38;5;241m.\u001b[39madd_motion_skel(\n\u001b[1;32m     48\u001b[0m         joints \u001b[38;5;241m=\u001b[39m joints[:, :\u001b[38;5;241m24\u001b[39m],\n\u001b[1;32m     49\u001b[0m         bones  \u001b[38;5;241m=\u001b[39m Skeleton_SMPLX22\u001b[38;5;241m.\u001b[39mbones,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m         offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     53\u001b[0m     )\n\u001b[0;32m---> 54\u001b[0m \u001b[43mvisualize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mlearn_betas.<locals>.visualize_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvisualize_results\u001b[39m():\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" This part is to visualize the results. You are supposed to ignore this part. \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     shape_wis3d \u001b[38;5;241m=\u001b[39m \u001b[43mWis3D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwis3d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSMPLX-parameters-beta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     shape_wis3d\u001b[38;5;241m.\u001b[39madd_motion_verts(\n\u001b[1;32m     37\u001b[0m         verts  \u001b[38;5;241m=\u001b[39m verts,\n\u001b[1;32m     38\u001b[0m         name   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas[:, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_component\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlower_bound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupper_bound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     39\u001b[0m         offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m     shape_wis3d\u001b[38;5;241m.\u001b[39madd_motion_mesh(\n\u001b[1;32m     42\u001b[0m         verts  \u001b[38;5;241m=\u001b[39m verts,\n\u001b[1;32m     43\u001b[0m         faces  \u001b[38;5;241m=\u001b[39m faces,\n\u001b[1;32m     44\u001b[0m         name   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface: betas[:, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_component\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlower_bound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupper_bound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m         offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     46\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "learn_betas(0)\n",
    "learn_betas(1)\n",
    "learn_betas(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the viewer.\n",
    "\n",
    "You will see that, the skeleton will mis-align with the mesh when the coefficients are very \"sharp\".\n",
    "Some of the coefficient control the height, the length of the limbs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/liu/anaconda3/envs/smplx/bin/wis3d\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/liu/anaconda3/envs/smplx/lib/python3.10/site-packages/wis3d/__init__.py\", line 35, in main\n",
      "    run_server(args.vis_dir, args.host, args.port, args.verbose)\n",
      "  File \"/home/liu/anaconda3/envs/smplx/lib/python3.10/site-packages/wis3d/server.py\", line 89, in run_server\n",
      "    visualizer = Visualizer(vis_dir, static_dir)\n",
      "  File \"/home/liu/anaconda3/envs/smplx/lib/python3.10/site-packages/wis3d/server.py\", line 11, in __init__\n",
      "    self.vis_dir = os.path.abspath(vis_dir)\n",
      "  File \"/home/liu/anaconda3/envs/smplx/lib/python3.10/posixpath.py\", line 379, in abspath\n",
      "    path = os.fspath(path)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n"
     ]
    }
   ],
   "source": [
    "# Start the server. (Remember to terminate the cell before going on.)\n",
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host 0.0.0.0 --port 19090\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‰πüÂèØ‰ª•Áõ¥Êé•Âú®ÁªàÁ´Ø‰∏≠ËøêË°å   **wis3d --vis_dir path/to/data_output/wis3d --host 0.0.0.0 --port 19090 --verbose True**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. global_orient | $\\theta_r\\in\\R^3$ (part of $\\theta \\in \\R^{3\\times24}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global orient control the face direction of the virtual human, which is also the \"rotation\" of the root joint.\n",
    "\n",
    "You may have to check [axis angle](https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation) before going on.\n",
    "For example, a vector $\\vec{r} = [x, y, z]$ represents a rotation around the axis $\\frac{\\vec{r}}{||\\vec{r}||}$ in radians $||\\vec{r}||$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn_orient():\n",
    "    def make_fake_data():\n",
    "        fake_orient = torch.zeros(B, 1, 3)\n",
    "        fake_orient[   : 50, :, 0] = torch.linspace(0, 2 * np.pi, 50).reshape(50, 1)  # about x-axis\n",
    "        fake_orient[ 50:100, :, 1] = torch.linspace(0, 2 * np.pi, 50).reshape(50, 1)  # about y-axis\n",
    "        fake_orient[100:150, :, :] = torch.linspace(0, 2 * np.pi, 50).reshape(50, 1, 1).repeat(1, 1, 3)  # about x=y=z\n",
    "        fake_orient[100:150, :, :] /= np.sqrt(3)  # Ensure the norm is 2pi.\n",
    "        return fake_orient\n",
    "    fake_orient = make_fake_data()\n",
    "\n",
    "    # Inference.\n",
    "    smpl_out = body_model(\n",
    "            betas         = torch.zeros(B, 10),     # shape coefficients\n",
    "            global_orient = fake_orient,            # axis-angle representation\n",
    "            body_pose     = torch.zeros(B, 21, 3),  # axis-angle representation\n",
    "            transl        = torch.zeros(B, 3),\n",
    "        )\n",
    "\n",
    "    # Check output.\n",
    "    joints : torch.Tensor = smpl_out.joints    \n",
    "    verts  : torch.Tensor = smpl_out.vertices  \n",
    "    faces  : np.ndarray   = body_model.faces   \n",
    "\n",
    "    def visualize_results():\n",
    "        \"\"\" This part is to visualize the results. You are supposed to ignore this part. \"\"\"\n",
    "        orient_wis3d = Wis3D(\n",
    "                pm.outputs / 'wis3d',\n",
    "                'SMPL-parameters-global_orient',\n",
    "            )\n",
    "\n",
    "        # Prepare the rotation axis.\n",
    "        axis_x   = torch.tensor([[0, 0, 0], [3, 0, 0]], dtype=torch.float32)\n",
    "        axis_y   = torch.tensor([[0, 0, 0], [0, 3, 0]], dtype=torch.float32)\n",
    "        axis_xyz = torch.tensor([[0, 0, 0], [1, 1, 1]], dtype=torch.float32)\n",
    "        axis_all = torch.concat(\n",
    "            [\n",
    "                axis_x.reshape(1, 2, 3).repeat(50, 1, 1),\n",
    "                axis_y.reshape(1, 2, 3).repeat(50, 1, 1),\n",
    "                axis_xyz.reshape(1, 2, 3).repeat(50, 1, 1),\n",
    "            ], dim = 0)\n",
    "        axis_all[:, :, :] += joints[:, [0], :] # move the axis to the root joints\n",
    "\n",
    "\n",
    "        orient_wis3d.add_vec_seq(\n",
    "            vecs = axis_all,\n",
    "            name = 'rotation axis',\n",
    "        )\n",
    "        orient_wis3d.add_motion_verts(\n",
    "            verts  = verts,\n",
    "            name   = f'vertices',\n",
    "            offset = 0,\n",
    "        )\n",
    "        orient_wis3d.add_motion_mesh(\n",
    "            verts  = verts,\n",
    "            faces  = faces,\n",
    "            name   = f'surface',\n",
    "            offset = 0,\n",
    "        )\n",
    "        orient_wis3d.add_motion_skel(\n",
    "            joints = joints[:, :24],\n",
    "            bones  = Skeleton_SMPLX22.bones,\n",
    "            colors = Skeleton_SMPLX22.bone_colors,\n",
    "            name   = f'skeleton',\n",
    "            offset = 0,\n",
    "        )\n",
    "    visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the effects of the changes on `global_orient`.\n",
    "\n",
    "Here, `learn_orient()` will rotate the digital human in three ways:\n",
    "\n",
    "1. `fake_orient[  0: 50]` = $[0, 0, 0] \\rightarrow [2\\pi,  0, 0 ]$, rotation about $x$-axis\n",
    "2. `fake_orient[ 50:100]` = $[0, 0, 0] \\rightarrow [ 0, 2œÄ, 0 ]$, rotation about $y$-axis\n",
    "3. `fake_orient[100:150]` = $[0, 0, 0] \\rightarrow [2œÄ, 2œÄ, 2œÄ]$, rotation about $x=y=z$ axis\n",
    "\n",
    "You are supposed to make sure you understand the axis-angle representation before going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mSet up Wis3D for SMPL-parameters-global_orient: 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "learn_orient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the Wis3D viewer.\n",
    "\n",
    "**You will see that, the rotation axis starts from the position of root joint, rather than the origin of the coordinates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host 0.0.0.0 --port 19090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still one thing you should know: the exact value of global orientation is related to the **coordinates** (e.g., camera coordinates, global coordinates) you are using. (So is the translation in SMPL.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. body_pose | $\\theta_b\\in\\R^{3\\times23}$ (part of $\\theta \\in \\R^{3\\times24}$)\n",
    "\n",
    "You should be sensitive to these numbers combinations: (23, 3), (23, 6), (23, 3, 3), (69,), (24, 3), (24, 6), (24, 3, 3), (72,). The tensor or array with these shapes are usually related to the body pose.\n",
    "\n",
    "Also, a pose is represented in the way of **kinematic chains**, the `body_pose` provide the **relative rotation of each joint to its parent joint**, and the SMPL model will solve a **forward kinematics** problem to get the final position of each joints, i.e. the final pose.\n",
    "\n",
    "> Check [this lecture (GAMES 105 Lec3)](https://www.bilibili.com/video/BV1GG4y1p7fF?p=3&vd_source=13807e82155f985591ed6f1b4e3434ed) if you are interested in the topic of forward/inverse kinematic.\n",
    "\n",
    "Sometimes we will group the `global_orient` and `body_pose` together as a 24 \"joints\" `pose`, and the `global_orient` is always the first element of this `pose`.\n",
    "\n",
    "Although in SMPL, the joint rotation is represented in the form of **axis-angle**, people are more likely to use an **6D-rotation** representation extracted from the 3x3 rotation matrix for a network to train. We will dive into this problem in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_body_pose(eg_path):\n",
    "    def load_eg_params(eg_path):\n",
    "        eg_params = np.load(eg_path, allow_pickle=True).item()\n",
    "        eg_body_pose_aa = torch.from_numpy(eg_params['body_pose'])  # (1, 23, 3)\n",
    "        return eg_body_pose_aa\n",
    "\n",
    "    def make_fake_data():\n",
    "        tgt_body_pose = load_eg_params(eg_path)  # (1, 23, 3)\n",
    "        grad_weights = torch.linspace(0, 1, B).reshape(B, 1, 1)  # (B, 1, 1)\n",
    "        fake_body_pose = grad_weights * tgt_body_pose  # (B, 23, 3)\n",
    "        return fake_body_pose\n",
    "\n",
    "    fake_body_pose = make_fake_data()  # (B, 23, 3)\n",
    "\n",
    "    # Inference.\n",
    "    smpl_out = body_model(\n",
    "            betas         = torch.zeros(B, 10),    # shape coefficients\n",
    "            global_orient = torch.zeros(B, 1, 3),  # axis-angle representation\n",
    "            body_pose     = fake_body_pose,        # axis-angle representation\n",
    "            transl        = torch.zeros(B, 3),\n",
    "        )\n",
    "\n",
    "    # Check output.\n",
    "    joints : torch.Tensor = smpl_out.joints    # (B, 45, 3)\n",
    "    verts  : torch.Tensor = smpl_out.vertices  # (B, 6890, 3)\n",
    "    faces  : np.ndarray   = body_model.faces   # (13776, 3)\n",
    "\n",
    "    def visualize_results():\n",
    "        \"\"\" This part is to visualize the results. You are supposed to ignore this part. \"\"\"\n",
    "        orient_wis3d = Wis3D(\n",
    "                pm.outputs / 'wis3d',\n",
    "                'SMPL-parameters-body_pose',\n",
    "            )\n",
    "\n",
    "        orient_wis3d.add_motion_verts(\n",
    "            verts  = verts,\n",
    "            name   = f'vertices',\n",
    "            offset = 0,\n",
    "        )\n",
    "        orient_wis3d.add_motion_mesh(\n",
    "            verts  = verts,\n",
    "            faces  = faces,\n",
    "            name   = f'surface',\n",
    "            offset = 0,\n",
    "        )\n",
    "        orient_wis3d.add_motion_skel(\n",
    "            joints = joints[:, :24],\n",
    "            bones  = Skeleton_SMPL24.bones,\n",
    "            colors = Skeleton_SMPL24.bone_colors,\n",
    "            name   = f'skeleton',\n",
    "            offset = 0,\n",
    "        )\n",
    "    visualize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_body_pose(pm.inputs / 'examples/ballerina.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. transl | $\\Gamma\\in\\R^{3}$\n",
    "\n",
    "Translation control the position of the virtual human in the 3D space. In camera coordinates, the translation usually represent the distance between the camera and the human. In global coordinates, the translation usually has the similar meaning as the movement of the human.\n",
    "\n",
    "We also use the word \"trajectory\" to represent the historical position of the root joint. Sometimes, the \"trajectory\" will be projected to the ground plane. Remember, the specific meaning of the translation is related to the specific work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_transl(rotation:bool = False):\n",
    "    def make_fake_data():\n",
    "        phase = torch.arange(50) / 50.0 * (2 * np.pi)  # 0 ~ 2ùúã\n",
    "\n",
    "        # Generate fake translation.\n",
    "        fake_transl = torch.zeros(B, 3)\n",
    "        # Part 1, [0, 50)\n",
    "        fake_transl[   : 25, 2] = torch.sin(phase[:25])  # along z-axis\n",
    "        fake_transl[ 25: 50, 1] = torch.sin(phase[:25])  # along y-axis\n",
    "        # Part 2, [50, 75) + [75, 100)\n",
    "        fake_transl[ 50:100, 1] = torch.sin(phase)       # along y-axis\n",
    "        fake_transl[ 50: 75, 0] = torch.sin(phase[::2])  # along y-axis\n",
    "        fake_transl[ 75:100, 2] = torch.sin(phase[::2])  # along y-axis\n",
    "        # Part 3, [100, 150)\n",
    "        fake_transl[100:150, 0] = torch.cos(phase) * phase / (2 * np.pi)\n",
    "        fake_transl[100:150, 2] = torch.sin(phase) * phase / (2 * np.pi)\n",
    "\n",
    "        # Generate fake rotation (if needed).\n",
    "        fake_orient = torch.zeros(B, 1, 3)\n",
    "        if rotation:\n",
    "            fake_orient[:, :, 1] = torch.linspace(0, 3 * (2 * np.pi), B).reshape(B, 1)  # about y-axis\n",
    "\n",
    "        return fake_transl, fake_orient\n",
    "\n",
    "    fake_transl, fake_orient = make_fake_data()\n",
    "\n",
    "    # Inference.\n",
    "    smpl_out = body_model(\n",
    "            betas         = torch.zeros(B, 10),     # shape coefficients\n",
    "            global_orient = fake_orient,            # axis-angle representation\n",
    "            body_pose     = torch.zeros(B, 23, 3),  # axis-angle representation\n",
    "            transl        = fake_transl,\n",
    "        )\n",
    "\n",
    "    # Check output.\n",
    "    joints : torch.Tensor = smpl_out.joints    # (B, 45, 3)\n",
    "    verts  : torch.Tensor = smpl_out.vertices  # (B, 6890, 3)\n",
    "    faces  : np.ndarray   = body_model.faces   # (13776, 3)\n",
    "\n",
    "    def visualize_results():\n",
    "        \"\"\" This part is to visualize the results. You are supposed to ignore this part. \"\"\"\n",
    "        transl_wis3d = Wis3D(\n",
    "                pm.outputs / 'wis3d',\n",
    "                'SMPL-parameters-transl',\n",
    "            )\n",
    "\n",
    "        transl_wis3d.add_traj(\n",
    "            positions = fake_transl,\n",
    "            name      = f'trajectory (rotating)' if rotation else 'trajectory',\n",
    "            offset    = 0,\n",
    "        )\n",
    "        transl_wis3d.add_motion_verts(\n",
    "            verts  = verts,\n",
    "            name   = f'vertices (rotating)' if rotation else 'vertices',\n",
    "            offset = 0,\n",
    "        )\n",
    "        transl_wis3d.add_motion_mesh(\n",
    "            verts  = verts,\n",
    "            faces  = faces,\n",
    "            name   = f'surface (rotating)' if rotation else 'surface',\n",
    "            offset = 0,\n",
    "        )\n",
    "        transl_wis3d.add_motion_skel(\n",
    "            joints = joints[:, :24],\n",
    "            bones  = Skeleton_SMPL24.bones,\n",
    "            colors = Skeleton_SMPL24.bone_colors,\n",
    "            name   = f'skeleton (rotating)' if rotation else 'skeleton',\n",
    "            offset = 0,\n",
    "        )\n",
    "    visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the effects of the changes on `transl`.\n",
    "\n",
    "Here, `learn_transl()` will make the digital human moves. Please check the code yourself and match the lines with the movements in the visualization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_transl(rotation=False)\n",
    "learn_transl(rotation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the Wis3D viewer.\n",
    "\n",
    "There are two things you should notice:\n",
    "\n",
    "1. The `transl` is defined in a static coordinate (compared to the ego coordinate of the agent). So the orientation changes will not affect the translation. Check the visualization results, you will find the trajectory of the rotating human and the non-rotating human are the same.\n",
    "2. The position of the root joint has small differences with the `transl` in the SMPL model, as the root joint won't be put on the origin of the coordinates in zero-pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host 0.0.0.0 --port 19090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [SMPL Project Page](https://smpl.is.tue.mpg.de/)\n",
    "- [SMPL-made-simple-FAQs](https://files.is.tue.mpg.de/black/talks/SMPL-made-simple-FAQs.pdf)\n",
    "- [SMPL wiki](https://meshcapade.wiki/SMPL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smplx(conda)",
   "language": "python",
   "name": "smplx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
